{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-02T08:57:14.432139Z",
     "iopub.status.busy": "2023-12-02T08:57:14.431748Z",
     "iopub.status.idle": "2023-12-02T08:57:14.860913Z",
     "shell.execute_reply": "2023-12-02T08:57:14.859854Z",
     "shell.execute_reply.started": "2023-12-02T08:57:14.432108Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Sentence prediction - Short reproducible example using a handful of data to demonstrate process not performance.\n",
    "\n",
    "Linear 1D layer model using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:57:14.947624Z",
     "iopub.status.busy": "2023-12-02T08:57:14.947114Z",
     "iopub.status.idle": "2023-12-02T08:57:17.105503Z",
     "shell.execute_reply": "2023-12-02T08:57:17.104025Z",
     "shell.execute_reply.started": "2023-12-02T08:57:14.947592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'auto_spell'...\n",
      "remote: Enumerating objects: 105, done.\u001b[K\n",
      "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
      "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
      "remote: Total 105 (delta 32), reused 88 (delta 18), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (105/105), 53.00 KiB | 4.42 MiB/s, done.\n",
      "Resolving deltas: 100% (32/32), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/kpapdac/auto_spell.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:57:18.913285Z",
     "iopub.status.busy": "2023-12-02T08:57:18.912780Z",
     "iopub.status.idle": "2023-12-02T08:57:19.076045Z",
     "shell.execute_reply": "2023-12-02T08:57:19.075026Z",
     "shell.execute_reply.started": "2023-12-02T08:57:18.913252Z"
    }
   },
   "outputs": [],
   "source": [
    "# path = '/kaggle/input/llm-detect-ai-generated-text/'\n",
    "# train_prompts = pd.read_csv(path + 'train_prompts.csv')#\n",
    "# train_essays = pd.read_csv(path + 'train_essays.csv')\n",
    "# test_essays = pd.read_csv(path + 'test_essays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:57:19.080793Z",
     "iopub.status.busy": "2023-12-02T08:57:19.079917Z",
     "iopub.status.idle": "2023-12-02T08:57:19.130258Z",
     "shell.execute_reply": "2023-12-02T08:57:19.128991Z",
     "shell.execute_reply.started": "2023-12-02T08:57:19.080734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_id</th>\n",
       "      <th>generated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>707</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  text\n",
       "prompt_id generated           \n",
       "0         0          707   707\n",
       "          1            1     1\n",
       "1         0          668   668\n",
       "          1            2     2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_essays.groupby(['prompt_id','generated']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T08:57:19.143174Z",
     "iopub.status.busy": "2023-12-02T08:57:19.142553Z",
     "iopub.status.idle": "2023-12-02T08:57:20.600908Z",
     "shell.execute_reply": "2023-12-02T08:57:20.599940Z",
     "shell.execute_reply.started": "2023-12-02T08:57:19.143140Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from auto_spell.auto_spell.src import model, optimize, textLoader, vocabulary\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T09:05:52.770674Z",
     "iopub.status.busy": "2023-12-02T09:05:52.769916Z",
     "iopub.status.idle": "2023-12-02T09:05:52.777906Z",
     "shell.execute_reply": "2023-12-02T09:05:52.776749Z",
     "shell.execute_reply.started": "2023-12-02T09:05:52.770638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1378, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_essays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T09:05:53.166611Z",
     "iopub.status.busy": "2023-12-02T09:05:53.166210Z",
     "iopub.status.idle": "2023-12-02T09:05:53.172920Z",
     "shell.execute_reply": "2023-12-02T09:05:53.171460Z",
     "shell.execute_reply.started": "2023-12-02T09:05:53.166578Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(train_essays, [0.6, 0.4], \n",
    "                                                            torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T09:05:53.803248Z",
     "iopub.status.busy": "2023-12-02T09:05:53.802861Z",
     "iopub.status.idle": "2023-12-02T09:05:53.810939Z",
     "shell.execute_reply": "2023-12-02T09:05:53.810046Z",
     "shell.execute_reply.started": "2023-12-02T09:05:53.803217Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gen_nongen_sent(fullset):\n",
    "    ser_sent = fullset.set_index('generated').text.str.split('.').explode()\n",
    "    ser_sent_gen = [sent for sent in ser_sent[(ser_sent.index==1)].tolist() if sent!='']\n",
    "    ser_sent_nongen = [sent for sent in ser_sent[(ser_sent.index==0)].tolist() if sent!=''][0:len(ser_sent_gen)]\n",
    "    gen_text = [(1, \\\n",
    "             ser_sent_gen[i]) \\\n",
    "            for i in range(len(ser_sent_gen))]\n",
    "    nongen_text = [(0, \\\n",
    "                ser_sent_nongen[i]) \\\n",
    "            for i in range(len(ser_sent_nongen))]\n",
    "    return [gen_text, nongen_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T09:05:54.582957Z",
     "iopub.status.busy": "2023-12-02T09:05:54.582020Z",
     "iopub.status.idle": "2023-12-02T09:05:54.591259Z",
     "shell.execute_reply": "2023-12-02T09:05:54.590298Z",
     "shell.execute_reply.started": "2023-12-02T09:05:54.582918Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gen_nongen(fullset, underpresent_multiplier):\n",
    "    gen_text = [(fullset[\n",
    "          (fullset.generated==1)].reset_index().iloc[i,:]['generated'], \\\n",
    "             fullset[\n",
    "          (fullset.generated==1)].reset_index().iloc[i,:]['text'][-1000:]) \\\n",
    "            for i in range(fullset[\n",
    "                                        (fullset.generated==1)].shape[0])]*underpresent_multiplier\n",
    "    nongen_text = [(fullset[\n",
    "             (fullset.generated==0)].reset_index().iloc[i,:]['generated'], \\\n",
    "                fullset[#(train_essays.prompt_id==1) & \\\n",
    "             (fullset.generated==0)].reset_index().iloc[i,:]['text'][-1000:]) \\\n",
    "               for i in range(fullset[\n",
    "                                       (fullset.generated==0)].shape[0])]\n",
    "    return [gen_text, nongen_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize in Small scale - step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T09:07:44.888117Z",
     "iopub.status.busy": "2023-12-02T09:07:44.887665Z",
     "iopub.status.idle": "2023-12-02T09:07:45.016652Z",
     "shell.execute_reply": "2023-12-02T09:07:45.015417Z",
     "shell.execute_reply.started": "2023-12-02T09:07:44.888082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is: 2.73775452375412\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.01s | valid accuracy    0.500 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.731295481324196\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.00s | valid accuracy    0.750 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.724315345287323\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.00s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.7162885665893555\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  0.00s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.7066370993852615\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  0.00s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "gen_nongen_train = [[(0,'This is my own text.'),\n",
    "                     (0,'I wrote this myself.')],\n",
    "                    [(1,'It is common knowledge that sky is blue.'),\n",
    "                     (1,'Most available sources state that EV cars are still far from production.')]]\n",
    "# gen_nongen_train = get_gen_nongen(train_dataset.dataset.loc[train_dataset.indices,:], \n",
    "#                                   int(0.1*train_dataset.dataset.loc[train_dataset.indices,:].shape[0]))\n",
    "# gen_nongen_test = get_gen_nongen(test_dataset.dataset.loc[test_dataset.indices,:], \n",
    "#                                   int(0.1*test_dataset.dataset.loc[test_dataset.indices,:].shape[0]))\n",
    "# gen_nongen_train = get_gen_nongen_sent(train_dataset.dataset.loc[train_dataset.indices,:])\n",
    "text_label_train = gen_nongen_train[0] + gen_nongen_train[1]\n",
    "voc = vocabulary.vocabulary()\n",
    "voc.tokenizer = 'basic_english'\n",
    "voc.get_vocab(text_label_train)\n",
    "voc.set_text_pipeline()\n",
    "voc.set_label_pipeline()\n",
    "voc.get_voc_size()\n",
    "voc.get_num_class(text_label_train)\n",
    "num_embeddings = voc.vocab_size\n",
    "embed_dim = 10\n",
    "num_class = 2\n",
    "mod = model.TextClassificationModel(num_embeddings, embed_dim, num_class)\n",
    "prep = textLoader.prepareTextLabelLoaderLogisticNN(text_label_train, 'sms', 'label', voc.text_pipeline, voc.label_pipeline)\n",
    "train_dataloader = DataLoader(text_label_train, batch_size=1, shuffle=False, collate_fn=prep.collate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "LR = 2\n",
    "optimizer = torch.optim.SGD(mod.parameters(), lr=LR)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# model(torch.tensor(voc.text_pipeline(text_label_train[0][1])), torch.tensor([0]))\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.mean())\n",
    "def train(epoch):\n",
    "    for idx, (label, text, offsets) in enumerate(train_dataloader):\n",
    "#         print(text)\n",
    "        total_acc, total_count = 0, 0\n",
    "        log_interval = 2\n",
    "        start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = mod(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(mod.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "#         for name, param in model.named_parameters():\n",
    "#             print(name, param.mean())\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "    #                 print(total_acc)\n",
    "        running_loss =+ loss.item() * text.size(0)\n",
    "#         print(running_loss)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "#             print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "#                 '| accuracy {:8.3f}'.format(epoch, idx, len(train_dataloader),\n",
    "#                                             total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "    return running_loss / len(train_dataloader)\n",
    "\n",
    "def evaluate():\n",
    "    mod.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(train_dataloader):\n",
    "            predicted_label = mod(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count\n",
    "\n",
    "total_accu = None\n",
    "loss_values = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    new_loss = train(epoch)\n",
    "    loss_values.append(new_loss)\n",
    "    print(f'Loss is: {new_loss}')\n",
    "    accu_val = evaluate()\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "        'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                        time.time() - epoch_start_time,\n",
    "                                        accu_val))\n",
    "    print('-' * 59)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# LR = 0.03\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "# prep = textLoader.prepareTextLabelLoaderLogisticNN(text_label_train, 'sms', 'label', voc.text_pipeline, voc.label_pipeline)\n",
    "# train_dataloader = DataLoader(text_label_train, batch_size=1, shuffle=False, collate_fn=prep.collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T09:06:08.956952Z",
     "iopub.status.busy": "2023-12-02T09:06:08.955765Z",
     "iopub.status.idle": "2023-12-02T09:06:10.220044Z",
     "shell.execute_reply": "2023-12-02T09:06:10.219022Z",
     "shell.execute_reply.started": "2023-12-02T09:06:08.956909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is: 2.753170371055603\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  0.01s | valid accuracy    0.500 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.745902180671692\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.7384449243545532\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.730266660451889\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.7207862436771393\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.7093355506658554\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.6951147317886353\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.6771507561206818\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.6542520821094513\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.624967783689499\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.5875563621520996\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  11 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.539978966116905\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  12 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.479931741952896\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  13 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.404941141605377\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  14 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.3125444650650024\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  15 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.200569197535515\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  16 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 2.0675134658813477\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  17 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 1.9129946827888489\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  18 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 1.738198772072792\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  19 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Loss is: 1.546238251030445\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  20 | time:  0.01s | valid accuracy    1.000 \n",
      "-----------------------------------------------------------\n",
      "Model test set:  2 2\n",
      "Data test set:  2 2\n"
     ]
    }
   ],
   "source": [
    "# gen_nongen_train = get_gen_nongen(train_dataset.dataset.loc[train_dataset.indices,:], \n",
    "#                                   int(0.1*train_dataset.dataset.loc[train_dataset.indices,:].shape[0]))\n",
    "# gen_nongen_test = get_gen_nongen(test_dataset.dataset.loc[test_dataset.indices,:], \n",
    "#                                   int(0.1*test_dataset.dataset.loc[test_dataset.indices,:].shape[0]))\n",
    "# gen_nongen_train = get_gen_nongen_sent(train_dataset.dataset.loc[train_dataset.indices,:])\n",
    "gen_nongen_train = [[(0,'This is my own text.'),\n",
    "                     (0,'I wrote this myself.')],\n",
    "                    [(1,'It is common knowledge that sky is blue.'),\n",
    "                     (1,'Most available sources state that EV cars are still far from production.')]]\n",
    "# gen_nongen_test = get_gen_nongen_sent(test_dataset.dataset.loc[test_dataset.indices,:])\n",
    "text_label_train = gen_nongen_train[0] + gen_nongen_train[1]\n",
    "# text_label_test = gen_nongen_test[0] + gen_nongen_test[1]\n",
    "voc = vocabulary.vocabulary()\n",
    "voc.tokenizer = 'basic_english'\n",
    "voc.get_vocab(text_label_train)\n",
    "voc.set_text_pipeline()\n",
    "voc.set_label_pipeline()\n",
    "voc.get_voc_size()\n",
    "voc.get_num_class(text_label_train)\n",
    "num_embeddings = voc.vocab_size\n",
    "embed_dim = 20\n",
    "num_class = 2\n",
    "\n",
    "mod = model.TextClassificationModel(num_embeddings, embed_dim, num_class)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "LR = 2\n",
    "optimizer = torch.optim.SGD(mod.parameters(), lr=LR)\n",
    "prep = textLoader.prepareTextLabelLoaderLogisticNN(text_label_train, 'sms', 'label', voc.text_pipeline, voc.label_pipeline)\n",
    "train_dataloader = DataLoader(text_label_train, batch_size=1, shuffle=False, collate_fn=prep.collate)\n",
    "# test_dataloader = DataLoader(text_label_test, batch_size=1, shuffle=False, collate_fn=prep.collate)\n",
    "opt = optimize.optimize(train_dataloader, train_dataloader, mod, criterion, optimizer, False)\n",
    "# opt = optimize(train_dataloader, test_dataloader, model, criterion, optimizer, True)\n",
    "opt.hypertuning(epochs=20)\n",
    "res = [opt.predict(text_label_train[i][1], voc.text_pipeline) for i in range(len(text_label_train))]\n",
    "print('Model test set: ', res.count(1), res.count(2)) #, res\n",
    "real = [text_label_train[i][0] for i in range(len(text_label_train))]\n",
    "print('Data test set: ', real.count(0), real.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T16:15:21.462399Z",
     "iopub.status.busy": "2023-12-01T16:15:21.461858Z",
     "iopub.status.idle": "2023-12-01T16:15:21.473141Z",
     "shell.execute_reply": "2023-12-01T16:15:21.471266Z",
     "shell.execute_reply.started": "2023-12-01T16:15:21.462359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.predict(\"Big cities have recently started doing \"\"CarFree\"\" days where no one is allowed to drive\", voc.text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T16:17:38.724997Z",
     "iopub.status.busy": "2023-12-01T16:17:38.724385Z",
     "iopub.status.idle": "2023-12-01T16:17:38.734607Z",
     "shell.execute_reply": "2023-12-01T16:17:38.733279Z",
     "shell.execute_reply.started": "2023-12-01T16:17:38.724954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.predict(\"\"\"The electrol college system is an unfair system, people don\\'t have the right to select their own president, they dont have the right to select a president.\"\"\", voc.text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
